{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Tags",
    "colab": {
      "name": "Copy of stochastic_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7C_Q2UbkGas"
      },
      "source": [
        "##**Stochastic Optimization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsbCH_XUJDCN"
      },
      "source": [
        "## Notebook Setup \n",
        "The following cell will install Drake, checkout the manipulation repository, and set up the path (only if necessary).\n",
        "- On Google's Colaboratory, this **will take approximately two minutes** on the first time it runs (to provision the machine), but should only need to reinstall once every 12 hours.  \n",
        "\n",
        "More details are available [here](http://manipulation.mit.edu/drake.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLnz0sRrSjOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bbc00b-b8d3-4de0-d900-b3f6f70783ef"
      },
      "source": [
        "import importlib\n",
        "import os, sys\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "if 'google.colab' in sys.modules and importlib.util.find_spec('manipulation') is None:\n",
        "    urlretrieve(f\"http://manipulation.csail.mit.edu/scripts/setup/setup_manipulation_colab.py\",\n",
        "                \"setup_manipulation_colab.py\")\n",
        "    from setup_manipulation_colab import setup_manipulation\n",
        "    setup_manipulation(manipulation_sha='fa5bcfb6367cd0cfda0e3d11e11854d68b39478a', drake_version='20201118', drake_build='nightly')\n",
        "\n",
        "from IPython import get_ipython\n",
        "running_as_notebook = get_ipython() and hasattr(get_ipython(), 'kernel')\n",
        "\n",
        "# setup ngrok server\n",
        "server_args = []\n",
        "if 'google.colab' in sys.modules:\n",
        "  server_args = ['--ngrok_http_tunnel']\n",
        "\n",
        "# start a single meshcat server instance to use for remainder of this notebook.\n",
        "from meshcat.servers.zmqserver import start_zmq_server_as_subprocess\n",
        "proc, zmq_url, web_url = start_zmq_server_as_subprocess(server_args=server_args)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt, mpld3\n",
        "if running_as_notebook:\n",
        "  mpld3.enable_notebook()\n",
        "\n",
        "import pydrake\n",
        "import meshcat\n",
        "import meshcat.geometry as g\n",
        "import meshcat.transformations as tf\n",
        "from pydrake.all import (Variable, Evaluate)\n",
        "\n",
        "def loss(theta):\n",
        "  x = theta[0]\n",
        "  y = theta[1]\n",
        "  eval = 2 * x ** 2 - 1.05 * x ** 4 + x ** 6 / 6 + x * y + y ** 2\n",
        "  return 0.25 * eval\n",
        "\n",
        "def generate_color_mat(color_vec, shape):\n",
        "  color_mat = np.tile(np.array(color_vec).astype(np.float32).reshape(3,1), (1, shape[1]))\n",
        "  return color_mat\n",
        "\n",
        "def visualize_loss(vis, loss, colormap='viridis', spacing=0.01, clip_min=None, clip_max=None):\n",
        "  # Create a grid of thetas and evaluate losses.\n",
        "  points = []\n",
        "  for i in np.arange(-3, 3, spacing):\n",
        "    for j in np.arange(-3, 3, spacing):\n",
        "      points.append([i,j,loss(np.array([i,j]))])\n",
        "  points = np.array(points).transpose()\n",
        "\n",
        "  # Normalize losses and color them according to colormap. \n",
        "  cmap = matplotlib.cm.get_cmap(colormap)\n",
        "  colors = []\n",
        "  min_loss = np.min(points[2,:]) if clip_min == None else clip_min\n",
        "  max_loss = np.max(points[2,:]) if clip_max == None else clip_max\n",
        "\n",
        "  for i in range(points.shape[1]):\n",
        "    normalized_loss = (points[2,i] - min_loss) / (max_loss - min_loss)\n",
        "    color = list(cmap(normalized_loss))[0:3]\n",
        "    colors.append(color)\n",
        "\n",
        "  colors = np.array(colors).transpose()\n",
        "\n",
        "  vis.delete()\n",
        "  vis[\"/Background\"].set_property('visible', False)\n",
        "  vis[\"/loss\"].set_object(g.PointCloud(points, colors, size=0.03))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEAD is now at fa5bcfb Merge pull request #111 from hjsuh94/rl/sets\n",
            "\n",
            "+ [[ 0 -ne 0 ]]\n",
            "+ command -v conda\n",
            "+ apt-get update -qq\n",
            "+ apt-get install -o APT::Acquire::Retries=4 -o Dpkg::Use-Pty=0 -qy --no-install-recommends lsb-release\n",
            "++ lsb_release -cs\n",
            "+ [[ bionic != \\b\\i\\o\\n\\i\\c ]]\n",
            "+ apt-get install -o APT::Acquire::Retries=4 -o Dpkg::Use-Pty=0 -qy --no-install-recommends ca-certificates gnupg\n",
            "+ APT_KEY_DONT_WARN_ON_DANGEROUS_USAGE=1\n",
            "+ apt-key adv -q --fetch-keys https://bazel.build/bazel-release.pub.gpg\n",
            "+ echo 'deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8'\n",
            "+ apt-get update -qq\n",
            "++ cat\n",
            "+ apt-get install -o APT::Acquire::Retries=4 -o Dpkg::Use-Pty=0 -qy --no-install-recommends bazel jupyter jupyter-nbconvert jupyter-notebook locales python3 python3-bs4 python3-dev python3-entrypoints python3-future python3-ipywidgets python3-jinja2 python3-jsonschema python3-numpy python3-pandas python3-pip python3-requests python3-retrying python3-setuptools python3-six python3-snowballstemmer python3-toolz python3-tqdm python3-wheel python3-widgetsnbextension tidy wget\n",
            "+ locale-gen en_US.UTF-8\n",
            "+ jupyter nbextension enable --system --py widgetsnbextension\n",
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n",
            "+ [[ -z en_US.UTF-8 ]]\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUTNJkCK1IDH"
      },
      "source": [
        "## The Three Hump Camel \n",
        "In this exercise, we'll implement our own versions of gradient descent and stochastic gradient descent! \n",
        "\n",
        "Our goal is to find the minima of the following function:\n",
        "\n",
        "$$l(x)= \\frac{1}{4}\\bigg(2x_1^2-1.05x_1^4+\\frac{x_1^6}{6}+x_1x_2+x_2^2\\bigg)$$\n",
        "\n",
        "Note that you can access this function using `loss(x)`.\n",
        "\n",
        "We have visualized the landscape of this function in meshcat if you run the cell below! You will notice the following things:\n",
        "\n",
        "1. This function has 3 local minima (hence, the name 'three hump camel')\n",
        "2. The global minima is located at $f([0,0])=0$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1GCQpPf1HwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9072a3-cca6-4d10-839f-03c8f9cefdf9"
      },
      "source": [
        "vis = meshcat.Visualizer(zmq_url)\n",
        "# The paramters are optimized for best visualization in meshcat. \n",
        "# For faster visualization, try increasing spacing. \n",
        "visualize_loss(vis, loss, colormap = 'viridis', spacing=0.02, clip_max=2.0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You can open the visualizer by visiting the following URL:\n",
            "http://172807b55fa6.ngrok.io/static/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nBpUQcfOcwF"
      },
      "source": [
        "## Gradient Descent\n",
        "\n",
        "As we saw in the lecture, one way of trying to find the minimum of $l(x)$ is to use explicit gradients and do gradient descent. \n",
        "\n",
        "$$x \\leftarrow x - \\eta\\bigg(\\frac{\\partial l(x)}{\\partial x}\\bigg)^T$$\n",
        "\n",
        "We've set up a basic outline of the gradient descent algoritm for you. Take a look at the following function `gradient_descent` that implements the following steps:\n",
        "\n",
        "1. Initialize $x\\in\\mathbb{R}^2$ at random from some bounded region.\n",
        "2. Until maximum iteration, update $x$ according to the rule. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH6DEMMA9cXP"
      },
      "source": [
        "def gradient_descent(rate, update_rule, initial_x=None, iter=1000):\n",
        "  \"\"\"gradient descent algorithm \n",
        "  @params: \n",
        "  - rate (float): eta variable of gradient descent.\n",
        "  - update_rule: a function with a signature update_rule(x, rate). \n",
        "  - initial_x: initial position for gradient descent. \n",
        "  - iter: number of iterations to run gradient descent for.\n",
        "  \"\"\"\n",
        "  # If no initial guess is supplied, then randomly choose one. \n",
        "  if initial_x is None:\n",
        "    x = -3 + 6.0 * np.random.rand(2)\n",
        "  else:\n",
        "    x = initial_x\n",
        "  # Compute loss for first parameter for visualization. \n",
        "  x_list = []\n",
        "  x_list.append([x[0], x[1], loss(x)])\n",
        "  # Loop through with gradient descent. \n",
        "  for i in range(iter):\n",
        "    # Update the parameters using update rule.\n",
        "    x = update_rule(x, rate)\n",
        "    x_list.append([x[0], x[1], loss(x)])\n",
        "  return np.array(x_list)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcIyb-iJRGHg"
      },
      "source": [
        "## Determinisitc Exact Gradients\n",
        "\n",
        "**Problem 9.1.a** [2 pts]: Let's first use the vanilla gradient descent algorithm with exact gradients. Below, you must implement the simple update function:\n",
        "\n",
        "$$x \\leftarrow x - \\eta\\bigg(\\frac{\\partial l(x)}{\\partial x}\\bigg)^T$$\n",
        "\n",
        "HINT: You can write down the gradient yourself, but remember you can also use drake's symbolic differentiation!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO7h13kCUc1a"
      },
      "source": [
        "def exact_gradient(x, rate):\n",
        "    \"\"\"\n",
        "    Update rule. Receive theta and update it with the next theta.\n",
        "    @params\n",
        "    - x: input variable x.\n",
        "    - rate: rate of descent, variable \"eta\". \n",
        "    @returns:\n",
        "    - updated variable x. \n",
        "    \"\"\"\n",
        "    x_var = Variable('x')\n",
        "    y_var = Variable('y')\n",
        "    L_xy = loss([x_var,y_var])\n",
        "    J = L_xy.Jacobian([x_var,y_var])\n",
        "    J_val = np.squeeze(np.array(Evaluate(J,{x_var:x[0], y_var:x[1]})),1)\n",
        "    x = x - rate*J_val\n",
        "    return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT1PCqWPTTy2"
      },
      "source": [
        "When you've completed the function, you can run the below cell to check the visualization! For this problem, the visualization has the following convention:\n",
        "- Red sphere is the initial guess \n",
        "- Green sphere is the final point after `iter` iterations. \n",
        "- Every updated parameter is drawn as smaller red cubes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEG6dKaxTbie"
      },
      "source": [
        "# Compute the trajectory. \n",
        "trajectory = gradient_descent(0.1, exact_gradient)\n",
        "vis[\"/traj\"].set_object(g.PointCloud(trajectory.transpose(), generate_color_mat([1, 0, 0], trajectory.transpose().shape), size=0.03))\n",
        "vis[\"/traj_line\"].set_object(g.Line(g.PointsGeometry(trajectory.transpose()), g.MeshBasicMaterial(color=0xff0000)))\n",
        "\n",
        "# Visualize the initial guess.\n",
        "vis[\"/traj_initial\"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0xff0000, reflectivity=0.8))\n",
        "vis[\"/traj_initial\"].set_transform(tf.translation_matrix(trajectory[0,:]))\n",
        "\n",
        "# Visualize the final point of the iteration.\n",
        "vis[\"/traj_final\"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0x00ff00, reflectivity=0.8))\n",
        "vis[\"/traj_final\"].set_transform(tf.translation_matrix(trajectory[-1,:]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT4O4yL7iuNg"
      },
      "source": [
        "If you've implemented it correctly, run the cell multiple times to see the behavior of gradient descent from different initial conditions. You should note that depending on where you started, you are deterministically stuck in the local minima that corresponds to its attraction region. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V8LydfhVMdJ"
      },
      "source": [
        "## Stochastic Approximation to Gradients\n",
        "\n",
        "**Problem 9.1.b** [2 pts]: One of the mindblowing facts we learned from the lecture was that we can actually do gradient descent without ever having true gradients of the loss function $l(x)$! \n",
        "\n",
        "Your job is to write down the following update function for gradient descent:\n",
        "\n",
        "$$x \\leftarrow x - \\eta\\big[l(x+w)-l(x)\\big]w$$\n",
        "\n",
        "where $w\\in\\mathbb{R}^2$ drawn from a Gaussian distribution, $w\\sim\\mathcal{N}(0,\\sigma^2=0.25)$. You can use `np.random.normal()` to draw from this distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVxvWu3lLYd"
      },
      "source": [
        "def approximated_gradient(x, rate):\n",
        "  \"\"\"\n",
        "  Update rule. Receive theta and update it with the next theta.\n",
        "  @params\n",
        "  - x: input variable x.\n",
        "  - rate: rate of descent, variable \"eta\". \n",
        "  @returns:\n",
        "  - updated varaible x. \n",
        "  \"\"\"\n",
        "  w = np.random.normal(0,0.5,2)\n",
        "  x = x - rate * (loss(x+w) - loss(x)) * w\n",
        "  return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg3ek5nz1ioL"
      },
      "source": [
        "Again, once you've implemented the function, run the below cell to visualize the trajectory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yku6xDTQQtAt"
      },
      "source": [
        "trajectory = gradient_descent(0.01, approximated_gradient, iter=10000)\n",
        "color_mat = np.tile(np.array([1.,0.,0]).astype(np.float32),(30,1)).transpose()\n",
        "vis[\"/traj\"].set_object(g.PointCloud(trajectory.transpose(), generate_color_mat([1, 0, 0], trajectory.transpose().shape), size=0.03))\n",
        "vis[\"/traj_line\"].set_object(g.Line(g.PointsGeometry(trajectory.transpose()), g.MeshBasicMaterial(color=0xff0000)))\n",
        "\n",
        "# Visualize the initial guess.\n",
        "vis[\"/traj_initial\"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0xff0000, reflectivity=0.8))\n",
        "vis[\"/traj_initial\"].set_transform(tf.translation_matrix(trajectory[0,:]))\n",
        "\n",
        "# Visualize the final point of the iteration.\n",
        "vis[\"/traj_final\"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0x00ff00, reflectivity=0.8))\n",
        "vis[\"/traj_final\"].set_transform(tf.translation_matrix(trajectory[-1,:]))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTEL3_ENl1oI"
      },
      "source": [
        "If you've implemented it correctly, take a moment to run it from multiple different conditions - the results are somewhat shocking.\n",
        "- With the right parameters ($\\sigma,\\eta$), this version of gradient descent is much better than the deterministic exact version at converging to global minima. (In fact, you'll sometimes see it hop out of one of the local minimas and converge to a global minima?)\n",
        "- But we never explicitly took derivatives!\n",
        "- (Side note): does this mean this way approximating gradients is the magical tool to everything? not quite. This version can be prone to getting stuck in saddle points!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRWAjIjmiVV"
      },
      "source": [
        "## Baselines \n",
        "\n",
        "**Problem 9.1.c** [4 pts]: We don't necessarily have to take finite differences to estimate the gradient. In fact, we could have subtracted our perturbed estimate from any function, as long as it is not a function of $w$! \n",
        "\n",
        "$$x \\leftarrow x - \\eta\\big[l(x+w)-b(x)\\big]w$$\n",
        "\n",
        "As a written problem, the problem is as follows: prove that on average, the difference in the updates (call it $\\mathbb{E}_w[\\Delta x$]) is approximately equal to the true analytical gradient. \n",
        "\n",
        "HINT: Use first-order taylor approximation of $l(x+w)$ (i.e. you may assume $w$ is quite small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdJXocpw3OTb"
      },
      "source": [
        "**Problem 9.1.d** [1 pts]: Finally, implement the update law above. The update rule is almost identical to 9.1.b except for the implementation of the baseline, so this is like a bonus question.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vjty4Tc9bZw"
      },
      "source": [
        "def approximated_gradient_with_baseline(x, rate, baseline):\n",
        "  \"\"\"\n",
        "  Update rule. Receive theta and update it with the next theta.\n",
        "  @params\n",
        "  - x: input variable x.\n",
        "  - rate: rate of descent, variable \"eta\". \n",
        "  - baseline: float for baseline.\n",
        "  @returns:\n",
        "  - updated varaible x. \n",
        "  \"\"\"\n",
        "  w = np.random.normal(0,0.5,2)\n",
        "  x = x - rate * (loss(x+w) - baseline(x)) * w\n",
        "  return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N1BgRG29jNV"
      },
      "source": [
        "As you proved in 9.1.c, adding a baseline does not change the mean of the update. However, it does change the variance!\n",
        "\n",
        "In the below code, you can play around with different values of the baseline to see what happens. Remember that the optimal value (smallest variance) of the baseline is $l(x)$. \n",
        "\n",
        "You should see that if the baseline is close to `loss(x)` (e.g. baseline is uniformly zero), there is no big difference with the solution you wrote on 9.1.b. However, when the baseline is far from `loss(x)` (e.g. baseline is uniformly 5), our path starts to look more like a random walk due to high variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IKbIy1P6a4k"
      },
      "source": [
        "def baseline(theta):\n",
        "    x = theta[0]\n",
        "    y = theta[1]\n",
        "    eval = 2 * x ** 2 + y ** 2\n",
        "    return 0.25 * eval\n",
        "\n",
        "def reduced_function(x, rate):\n",
        "  return approximated_gradient_with_baseline(x, rate, baseline)\n",
        "\n",
        "trajectory = gradient_descent(0.01, reduced_function, iter=10000)\n",
        "color_mat = np.tile(np.array([1.,0.,0]).astype(np.float32),(30,1)).transpose()\n",
        "vis[\"/traj\"].set_object(g.PointCloud(trajectory.transpose(), generate_color_mat([1, 0, 0], trajectory.transpose().shape), size=0.03))\n",
        "vis[\"/traj_line\"].set_object(g.Line(g.PointsGeometry(trajectory.transpose()), g.MeshBasicMaterial(color=0xff0000)))\n",
        "\n",
        "vis[\"/traj_initial\"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0x00ff00, reflectivity=0.8))\n",
        "vis[\"/traj_initial\"].set_transform(tf.translation_matrix(trajectory[0,:]))\n",
        "\n",
        "vis[\"/traj_final\"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0xff0000, reflectivity=0.8))\n",
        "vis[\"/traj_final\"].set_transform(tf.translation_matrix(trajectory[-1,:]))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwE8yNg58VQN"
      },
      "source": [
        "## How will this notebook be Graded?\n",
        "\n",
        "If you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n",
        "\n",
        "For submission of this assignment, you must do two things. \n",
        "- Download and submit the notebook `stochastic_optimization.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n",
        "- Write down your answers to 9.1.c to a separately pdf file and submit it to Gradescope's written submission section. \n",
        "\n",
        "We will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n",
        "- [2 pts] 9.1.a must be implemented correctly.\n",
        "- [2 pts] 9.1.b must be implemented correctly.\n",
        "- [4 pts] 9.1.c is answered correctly.\n",
        "- [1 pts] 9.1.d must be implemented correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQISVdEG9NoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06475a63-4358-4094-f674-a12898f5814c"
      },
      "source": [
        "from manipulation.exercises.rl.test_stochastic_optimization import TestStochasticOptimization\n",
        "from manipulation.exercises.grader import Grader \n",
        "\n",
        "Grader.grade_output([TestStochasticOptimization], [locals()], 'results.json')\n",
        "Grader.print_test_results('results.json')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total score is 5/5.\n",
            "\n",
            "Score for Test approximated gradient function is 2/2.\n",
            "\n",
            "Score for Test approximated gradient with baseline function is 1/1.\n",
            "\n",
            "Score for Test exact gradient function is 2/2.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpOVrgoQK1T9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}